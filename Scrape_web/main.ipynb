{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1a78789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Hugging Face – The AI community building the future.\n",
      "Links found: ['/', '/models', '/datasets', '/spaces', '/posts']\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "    # Remove scripts and irrelevant tags\n",
    "    for tag in soup([\"script\", \"style\", \"img\", \"input\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    links = [a.get('href') for a in soup.find_all('a') if a.get('href')]\n",
    "\n",
    "    return title, text, links\n",
    "\n",
    "# Try it out\n",
    "title, text, links = scrape_website(\"https://huggingface.co\")\n",
    "print(\"Title:\", title)\n",
    "print(\"Links found:\", links[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def pick_relevant_links(links, website_name):\n",
    "    prompt = f\"\"\"\n",
    "Here is a list of links from {website_name}:\n",
    "{links}\n",
    "\n",
    "Which of these would be most useful for writing a company brochure? \n",
    "Pick only relevant links (e.g. About, Team, Products, Careers), and return only the exact links.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2:1b',\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c2052aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful Links:\n",
      " Here are the relevant links that could be useful for writing a company brochure:\n",
      "\n",
      "1. /docs/huggingface_hub\n",
      "2. /about\n",
      "3. /team\n",
      "4. /products\n",
      "5. /careers\n"
     ]
    }
   ],
   "source": [
    "useful_links = pick_relevant_links(links, \"huggingface.co\")\n",
    "print(\"Useful Links:\\n\", useful_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09af463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "def scrape_useful_pages(base_url, useful_links_text):\n",
    "    pages = {}\n",
    "    for line in useful_links_text.strip().splitlines():\n",
    "        link = line.strip()\n",
    "        full_url = urljoin(base_url, link)\n",
    "        try:\n",
    "            title, text, _ = scrape_website(full_url)\n",
    "            pages[full_url] = {\"title\": title, \"text\": text}\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to scrape {full_url}: {e}\")\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f25ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages scraped: ['https://huggingface.co/Here are the relevant links that could be useful for writing a company brochure:', 'https://huggingface.co', 'https://huggingface.co/1. /docs/huggingface_hub', 'https://huggingface.co/2. /about', 'https://huggingface.co/3. /team', 'https://huggingface.co/4. /products', 'https://huggingface.co/5. /careers']\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://huggingface.co\"\n",
    "scraped_pages = scrape_useful_pages(base_url, useful_links)\n",
    "print(\"Pages scraped:\", list(scraped_pages.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc39b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_content = \"\"\n",
    "for url, data in scraped_pages.items():\n",
    "    combined_content += f\"\\n## From {url}\\n\"\n",
    "    combined_content += data['text'][:3000]  # Optional: limit very long pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56a1ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brochure_with_ollama(content, company_name):\n",
    "    prompt = f\"\"\"\n",
    "You're a professional brochure writer.\n",
    "\n",
    "Using the following content scraped from {company_name}'s website, write a brochure in **Markdown** format.\n",
    "\n",
    "It should highlight the company’s mission, products, team, and career opportunities.\n",
    "\n",
    "Use clear headings and bullet points where appropriate.\n",
    "\n",
    "Here is the content:\n",
    "{content}\n",
    "\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2:1b',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454a3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b940b718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Hugging Face: Where AI Meets Community\n",
      "=====================================================\n",
      "\n",
      "## About Us\n",
      "------------\n",
      "\n",
      "Hugging Face is a leading platform for machine learning (ML) and artificial intelligence (AI). We're a community-driven organization that's passionate about building the future of ML.\n",
      "\n",
      "## Mission\n",
      "----------\n",
      "\n",
      "Our mission is to make AI accessible, inclusive, and collaborative. We believe that ML should be used to solve real-world problems, not just in research or academia.\n",
      "\n",
      "## Models\n",
      "--------\n",
      "\n",
      "We have an incredible library of models, covering a wide range of tasks such as:\n",
      "\n",
      "* Vision: Object detection, segmentation, classification, and generation\n",
      "* Natural Language Processing (NLP): Text classification, sentiment analysis, language translation, and more\n",
      "* Music Generation: Generating high-quality music using state-of-the-art models\n",
      "\n",
      "## Datasets\n",
      "------------\n",
      "\n",
      "We offer a vast collection of public datasets, including:\n",
      "\n",
      "* Computer Vision: Image classification, object detection, segmentation, and generation\n",
      "* NLP: Sentiment analysis, language translation, text classification, and more\n",
      "* Audio and Music: Audio classification, music generation, and audio processing\n",
      "\n",
      "## Spaces\n",
      "---------\n",
      "\n",
      "Our platform is home to many communities, where users can collaborate on ML projects, share knowledge, and get feedback.\n",
      "\n",
      "## Products\n",
      "----------\n",
      "\n",
      "We offer several products that make it easy for developers to integrate our models and datasets into their applications:\n",
      "\n",
      "* **Hugging Face Transformers**: A collection of pre-trained transformers for various NLP tasks\n",
      "* **Hugging Face Datasets**: A library of public datasets for computer vision and NLP tasks\n",
      "* **Hugging Face Inference Endpoints**: Optimized inference endpoints for deploying models in production environments\n",
      "\n",
      "## Careers\n",
      "----------\n",
      "\n",
      "We're always looking for talented individuals to join our team. If you're passionate about ML, we want to hear from you!\n",
      "\n",
      "### Team Members\n",
      "-----------------\n",
      "\n",
      "Our team consists of experts in various areas of AI, including:\n",
      "\n",
      "* **Models**: Our engineers and researchers develop new models and improve existing ones.\n",
      "* **Datasets**: We curate and maintain our vast library of public datasets.\n",
      "* **Community Engagement**: We work closely with the community to ensure that our platform is inclusive and effective.\n",
      "\n",
      "### Join Us\n",
      "--------------\n",
      "\n",
      "If you're interested in joining our team, please visit our website for more information on available roles and how to apply.\n"
     ]
    }
   ],
   "source": [
    "brochure_md = generate_brochure_with_ollama(combined_content, \"Hugging Face\")\n",
    "print(brochure_md)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
